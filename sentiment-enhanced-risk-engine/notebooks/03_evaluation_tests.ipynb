{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0003070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56e7d6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = pd.read_csv(\"../data/processed/baseline_results.csv\", parse_dates=[\"Date\"])\n",
    "sentiment = pd.read_csv(\"../data/processed/sentiment_results.csv\", parse_dates=[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1738f769",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [baseline, sentiment]:\n",
    "    df[\"violation_95\"] = (df[\"y_real\"] < df[\"VaR_95\"]).astype(int)\n",
    "    df[\"violation_99\"] = (df[\"y_real\"] < df[\"VaR_99\"]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a804500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kupiec_test(violations, alpha):\n",
    "    T = len(violations)\n",
    "    x = violations.sum()\n",
    "    p_hat = x / T\n",
    "\n",
    "    if p_hat == 0 or p_hat == 1:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    LR = -2 * (\n",
    "        (T - x) * np.log((1 - alpha)/(1 - p_hat)) +\n",
    "        x * np.log(alpha/p_hat)\n",
    "    )\n",
    "\n",
    "    p_value = 1 - chi2.cdf(LR, df=1)\n",
    "\n",
    "    return LR, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eab6f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline 95%:  LR = 7.8118834057741395 p-value = 0.005190378179801058\n",
      "Sentiment 95%: LR = 22.181474705359292 p-value = 2.480557519168869e-06\n",
      "Baseline 99%:  LR = 0.03971167842775736 p-value = 0.842045371602491\n",
      "Sentiment 99%: LR = 0.8247187634022 p-value = 0.3638041128228918\n"
     ]
    }
   ],
   "source": [
    "# 95%\n",
    "LR_b_95, p_b_95 = kupiec_test(baseline[\"violation_95\"], 0.05)\n",
    "LR_s_95, p_s_95 = kupiec_test(sentiment[\"violation_95\"], 0.05)\n",
    "\n",
    "# 99%\n",
    "LR_b_99, p_b_99 = kupiec_test(baseline[\"violation_99\"], 0.01)\n",
    "LR_s_99, p_s_99 = kupiec_test(sentiment[\"violation_99\"], 0.01)\n",
    "\n",
    "print(\"Baseline 95%:  LR =\", LR_b_95, \"p-value =\", p_b_95)\n",
    "print(\"Sentiment 95%: LR =\", LR_s_95, \"p-value =\", p_s_95)\n",
    "\n",
    "print(\"Baseline 99%:  LR =\", LR_b_99, \"p-value =\", p_b_99)\n",
    "print(\"Sentiment 99%: LR =\", LR_s_99, \"p-value =\", p_s_99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0422aead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "def christoffersen_ind_test(violations):\n",
    "    v = np.asarray(violations, dtype=int)\n",
    "\n",
    "    # lagged violations\n",
    "    v0 = v[:-1]\n",
    "    v1 = v[1:]\n",
    "\n",
    "    # transition counts\n",
    "    n00 = np.sum((v0 == 0) & (v1 == 0))\n",
    "    n01 = np.sum((v0 == 0) & (v1 == 1))\n",
    "    n10 = np.sum((v0 == 1) & (v1 == 0))\n",
    "    n11 = np.sum((v0 == 1) & (v1 == 1))\n",
    "\n",
    "    # transition probabilities\n",
    "    pi01 = n01 / (n00 + n01) if (n00 + n01) > 0 else 0\n",
    "    pi11 = n11 / (n10 + n11) if (n10 + n11) > 0 else 0\n",
    "    pi1  = (n01 + n11) / (n00 + n01 + n10 + n11)\n",
    "\n",
    "    # avoid log(0)\n",
    "    eps = 1e-12\n",
    "    pi01 = np.clip(pi01, eps, 1-eps)\n",
    "    pi11 = np.clip(pi11, eps, 1-eps)\n",
    "    pi1  = np.clip(pi1,  eps, 1-eps)\n",
    "\n",
    "    # log-likelihood under independence\n",
    "    L0 = (n00 + n10) * np.log(1 - pi1) + (n01 + n11) * np.log(pi1)\n",
    "\n",
    "    # log-likelihood under Markov alternative\n",
    "    L1 = (\n",
    "        n00 * np.log(1 - pi01) +\n",
    "        n01 * np.log(pi01) +\n",
    "        n10 * np.log(1 - pi11) +\n",
    "        n11 * np.log(pi11)\n",
    "    )\n",
    "\n",
    "    LR_ind = -2 * (L0 - L1)\n",
    "    p_value = 1 - chi2.cdf(LR_ind, df=1)\n",
    "\n",
    "    return LR_ind, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "497ba525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline 95% IND:  LR = 0.0881901203565576 p = 0.7664907762626274\n",
      "Sentiment 95% IND: LR = 0.04438491881558093 p = 0.8331390999837467\n",
      "Baseline 99% IND:  LR = 6.680451997050994 p = 0.009747590405772999\n",
      "Sentiment 99% IND: LR = 1.4257082417011873 p = 0.23246613471076794\n"
     ]
    }
   ],
   "source": [
    "# 95% (alpha = 0.05)\n",
    "LR_b_95_ind, p_b_95_ind = christoffersen_ind_test(baseline[\"violation_95\"])\n",
    "LR_s_95_ind, p_s_95_ind = christoffersen_ind_test(sentiment[\"violation_95\"])\n",
    "\n",
    "# 99% (alpha = 0.01)\n",
    "LR_b_99_ind, p_b_99_ind = christoffersen_ind_test(baseline[\"violation_99\"])\n",
    "LR_s_99_ind, p_s_99_ind = christoffersen_ind_test(sentiment[\"violation_99\"])\n",
    "\n",
    "print(\"Baseline 95% IND:  LR =\", LR_b_95_ind, \"p =\", p_b_95_ind)\n",
    "print(\"Sentiment 95% IND: LR =\", LR_s_95_ind, \"p =\", p_s_95_ind)\n",
    "\n",
    "print(\"Baseline 99% IND:  LR =\", LR_b_99_ind, \"p =\", p_b_99_ind)\n",
    "print(\"Sentiment 99% IND: LR =\", LR_s_99_ind, \"p =\", p_s_99_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ffbbc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DM test 95%\n",
      "DM statistic: 1.3265121150423138\n",
      "p-value: 0.18467012491197066\n",
      "Mean loss difference (sent - base): 4.360323912979745e-05\n",
      "DM test 99%\n",
      "DM statistic: 1.21192909306439\n",
      "p-value: 0.2255395244128371\n",
      "Mean loss difference (sent - base): 4.0096167127662706e-05\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Keep only common dates\n",
    "common_dates = baseline[\"Date\"].isin(sentiment[\"Date\"])\n",
    "baseline = baseline[common_dates].copy()\n",
    "\n",
    "sentiment = sentiment[sentiment[\"Date\"].isin(baseline[\"Date\"])].copy()\n",
    "\n",
    "# Sort to ensure same order\n",
    "baseline = baseline.sort_values(\"Date\").reset_index(drop=True)\n",
    "sentiment = sentiment.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "def quantile_loss(y, q, alpha):\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    q = np.asarray(q, dtype=float)\n",
    "    indicator = (y < q).astype(int)\n",
    "    return (alpha - indicator) * (y - q)\n",
    "\n",
    "def dm_test(loss_diff):\n",
    "    \"\"\"\n",
    "    loss_diff = L_sentiment - L_baseline\n",
    "    H0: mean(loss_diff) = 0\n",
    "    \"\"\"\n",
    "    d = np.asarray(loss_diff, dtype=float)\n",
    "    T = len(d)\n",
    "\n",
    "    d_bar = d.mean()\n",
    "    var_d = d.var(ddof=1)\n",
    "\n",
    "    if var_d == 0:\n",
    "        return np.nan, np.nan, d_bar\n",
    "\n",
    "    DM_stat = d_bar / np.sqrt(var_d / T)\n",
    "    p_value = 2 * (1 - norm.cdf(abs(DM_stat)))\n",
    "\n",
    "    return DM_stat, p_value, d_bar\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "L_base_95 = quantile_loss(\n",
    "    baseline[\"y_real\"],\n",
    "    baseline[\"VaR_95\"],\n",
    "    alpha\n",
    ")\n",
    "\n",
    "L_sent_95 = quantile_loss(\n",
    "    sentiment[\"y_real\"],\n",
    "    sentiment[\"VaR_95\"],\n",
    "    alpha\n",
    ")\n",
    "\n",
    "loss_diff_95 = L_sent_95 - L_base_95\n",
    "\n",
    "DM_95, p_95, mean_diff_95 = dm_test(loss_diff_95)\n",
    "\n",
    "print(\"DM test 95%\")\n",
    "print(\"DM statistic:\", DM_95)\n",
    "print(\"p-value:\", p_95)\n",
    "print(\"Mean loss difference (sent - base):\", mean_diff_95)\n",
    "\n",
    "alpha = 0.01\n",
    "\n",
    "L_base_99 = quantile_loss(\n",
    "    baseline[\"y_real\"],\n",
    "    baseline[\"VaR_99\"],\n",
    "    alpha\n",
    ")\n",
    "\n",
    "L_sent_99 = quantile_loss(\n",
    "    sentiment[\"y_real\"],\n",
    "    sentiment[\"VaR_99\"],\n",
    "    alpha\n",
    ")\n",
    "\n",
    "loss_diff_99 = L_sent_99 - L_base_99\n",
    "\n",
    "DM_99, p_99, mean_diff_99 = dm_test(loss_diff_99)\n",
    "\n",
    "print(\"DM test 99%\")\n",
    "print(\"DM statistic:\", DM_99)\n",
    "print(\"p-value:\", p_99)\n",
    "print(\"Mean loss difference (sent - base):\", mean_diff_99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e65a097",
   "metadata": {},
   "source": [
    "Eval: ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d7dfee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ES empirical evaluation function (non-Acerbi\u2013Szekely)\n",
    "def evaluate_es_empirical(df: pd.DataFrame, alpha: float, y_col: str = \"y_real\"):\n",
    "    \"\"\"\n",
    "    Empirical ES evaluation:\n",
    "    1) VaR violations: y_real <= VaR_alpha\n",
    "    2) Realized tail mean: mean(y_real | violation)\n",
    "    3) Compare predicted ES with realized tail mean\n",
    "    4) ES Bias / MAE / RMSE (on violation days)\n",
    "    \"\"\"\n",
    "    level = int(alpha * 100)\n",
    "    var_col = f\"VaR_{level}\"\n",
    "    es_col = f\"ES_{level}\"\n",
    "\n",
    "    required = [y_col, var_col, es_col]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns for {level}%: {missing}\")\n",
    "\n",
    "    x = df[required].dropna().copy()\n",
    "    n = len(x)\n",
    "\n",
    "    # 1) Identify VaR violations\n",
    "    violations = x[y_col] <= x[var_col]\n",
    "    n_viol = int(violations.sum())\n",
    "    viol_rate = n_viol / n if n > 0 else np.nan\n",
    "\n",
    "    print(f\"\\n--- ES Evaluation @ {level}% ---\")\n",
    "    print(f\"Observations: {n}\")\n",
    "    print(f\"VaR violations: {n_viol} ({viol_rate:.4%})\")\n",
    "\n",
    "    if n_viol == 0:\n",
    "        print(\"No VaR violations -> ES metrics cannot be computed.\")\n",
    "        return {\n",
    "            \"alpha\": alpha,\n",
    "            \"n_obs\": n,\n",
    "            \"n_viol\": n_viol,\n",
    "            \"viol_rate\": viol_rate,\n",
    "            \"realized_tail_mean\": np.nan,\n",
    "            \"pred_es_tail_mean\": np.nan,\n",
    "            \"tail_mean_gap\": np.nan,\n",
    "            \"es_bias\": np.nan,\n",
    "            \"es_mae\": np.nan,\n",
    "            \"es_rmse\": np.nan,\n",
    "        }\n",
    "\n",
    "    tail = x.loc[violations, [y_col, es_col]].copy()\n",
    "\n",
    "    # 2) Realized tail mean\n",
    "    realized_tail_mean = tail[y_col].mean()\n",
    "\n",
    "    # 3) Compare predicted ES with realized tail mean\n",
    "    pred_es_tail_mean = tail[es_col].mean()\n",
    "    tail_mean_gap = pred_es_tail_mean - realized_tail_mean\n",
    "\n",
    "    # 4) ES metrics on violation days\n",
    "    errors = tail[es_col] - tail[y_col]\n",
    "    es_bias = errors.mean()\n",
    "    es_mae = errors.abs().mean()\n",
    "    es_rmse = np.sqrt((errors ** 2).mean())\n",
    "\n",
    "    print(f\"Realized tail mean (y_real | violation): {realized_tail_mean:.6f}\")\n",
    "    print(f\"Predicted ES mean on violations:         {pred_es_tail_mean:.6f}\")\n",
    "    print(f\"Tail-mean gap (ES_pred - realized):      {tail_mean_gap:.6f}\")\n",
    "    print(f\"ES Bias  (mean(ES_pred - y_real)):       {es_bias:.6f}\")\n",
    "    print(f\"ES MAE   (mean(|ES_pred - y_real|)):     {es_mae:.6f}\")\n",
    "    print(f\"ES RMSE  (sqrt(mean((ES_pred - y_real)^2))): {es_rmse:.6f}\")\n",
    "\n",
    "    # 6) Interpretation output\n",
    "    print(\"Interpretation:\")\n",
    "    if tail_mean_gap > 0:\n",
    "        print(\"- ES is less negative than realized tail mean -> tail risk is underestimated.\")\n",
    "    elif tail_mean_gap < 0:\n",
    "        print(\"- ES is more negative than realized tail mean -> tail risk estimate is conservative.\")\n",
    "    else:\n",
    "        print(\"- ES mean matches realized tail mean exactly.\")\n",
    "\n",
    "    return {\n",
    "        \"alpha\": alpha,\n",
    "        \"n_obs\": n,\n",
    "        \"n_viol\": n_viol,\n",
    "        \"viol_rate\": viol_rate,\n",
    "        \"realized_tail_mean\": realized_tail_mean,\n",
    "        \"pred_es_tail_mean\": pred_es_tail_mean,\n",
    "        \"tail_mean_gap\": tail_mean_gap,\n",
    "        \"es_bias\": es_bias,\n",
    "        \"es_mae\": es_mae,\n",
    "        \"es_rmse\": es_rmse,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df3fecff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline ===\n",
      "\n",
      "--- ES Evaluation @ 95% ---\n",
      "Observations: 1522\n",
      "VaR violations: 101 (6.6360%)\n",
      "Realized tail mean (y_real | violation): -0.026262\n",
      "Predicted ES mean on violations:         -0.027861\n",
      "Tail-mean gap (ES_pred - realized):      -0.001598\n",
      "ES Bias  (mean(ES_pred - y_real)):       -0.001598\n",
      "ES MAE   (mean(|ES_pred - y_real|)):     0.008643\n",
      "ES RMSE  (sqrt(mean((ES_pred - y_real)^2))): 0.016601\n",
      "Interpretation:\n",
      "- ES is more negative than realized tail mean -> tail risk estimate is conservative.\n",
      "\n",
      "--- ES Evaluation @ 99% ---\n",
      "Observations: 1522\n",
      "VaR violations: 16 (1.0512%)\n",
      "Realized tail mean (y_real | violation): -0.050760\n",
      "Predicted ES mean on violations:         -0.058280\n",
      "Tail-mean gap (ES_pred - realized):      -0.007519\n",
      "ES Bias  (mean(ES_pred - y_real)):       -0.007519\n",
      "ES MAE   (mean(|ES_pred - y_real|)):     0.012971\n",
      "ES RMSE  (sqrt(mean((ES_pred - y_real)^2))): 0.016545\n",
      "Interpretation:\n",
      "- ES is more negative than realized tail mean -> tail risk estimate is conservative.\n"
     ]
    }
   ],
   "source": [
    "#Load baseline results and evaluate ES at 95% and 99%\n",
    "baseline_path = \"../data/processed/baseline_results.csv\"\n",
    "baseline_df = pd.read_csv(baseline_path)\n",
    "\n",
    "if \"Date\" in baseline_df.columns:\n",
    "    baseline_df[\"Date\"] = pd.to_datetime(baseline_df[\"Date\"], errors=\"coerce\")\n",
    "    baseline_df = baseline_df.sort_values(\"Date\")\n",
    "\n",
    "print(\"=== Baseline ===\")\n",
    "baseline_95 = evaluate_es_empirical(baseline_df, alpha=0.95, y_col=\"y_real\")\n",
    "baseline_99 = evaluate_es_empirical(baseline_df, alpha=0.99, y_col=\"y_real\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "433de9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sentiment ===\n",
      "\n",
      "--- ES Evaluation @ 95% ---\n",
      "Observations: 1533\n",
      "VaR violations: 120 (7.8278%)\n",
      "Realized tail mean (y_real | violation): -0.024570\n",
      "Predicted ES mean on violations:         -0.025258\n",
      "Tail-mean gap (ES_pred - realized):      -0.000689\n",
      "ES Bias  (mean(ES_pred - y_real)):       -0.000689\n",
      "ES MAE   (mean(|ES_pred - y_real|)):     0.008222\n",
      "ES RMSE  (sqrt(mean((ES_pred - y_real)^2))): 0.014203\n",
      "Interpretation:\n",
      "- ES is more negative than realized tail mean -> tail risk estimate is conservative.\n",
      "\n",
      "--- ES Evaluation @ 99% ---\n",
      "Observations: 1533\n",
      "VaR violations: 19 (1.2394%)\n",
      "Realized tail mean (y_real | violation): -0.046428\n",
      "Predicted ES mean on violations:         -0.045471\n",
      "Tail-mean gap (ES_pred - realized):      0.000957\n",
      "ES Bias  (mean(ES_pred - y_real)):       0.000957\n",
      "ES MAE   (mean(|ES_pred - y_real|)):     0.011725\n",
      "ES RMSE  (sqrt(mean((ES_pred - y_real)^2))): 0.017223\n",
      "Interpretation:\n",
      "- ES is less negative than realized tail mean -> tail risk is underestimated.\n"
     ]
    }
   ],
   "source": [
    "#Load sentiment results and evaluate ES at 95% and 99%\n",
    "sentiment_path = \"../data/processed/sentiment_results.csv\"\n",
    "sentiment_df = pd.read_csv(sentiment_path)\n",
    "\n",
    "if \"Date\" in sentiment_df.columns:\n",
    "    sentiment_df[\"Date\"] = pd.to_datetime(sentiment_df[\"Date\"], errors=\"coerce\")\n",
    "    sentiment_df = sentiment_df.sort_values(\"Date\")\n",
    "\n",
    "print(\"=== Sentiment ===\")\n",
    "sentiment_95 = evaluate_es_empirical(sentiment_df, alpha=0.95, y_col=\"y_real\")\n",
    "sentiment_99 = evaluate_es_empirical(sentiment_df, alpha=0.99, y_col=\"y_real\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f743732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Level</th>\n",
       "      <th>n_obs</th>\n",
       "      <th>n_viol</th>\n",
       "      <th>viol_rate</th>\n",
       "      <th>realized_tail_mean</th>\n",
       "      <th>pred_es_tail_mean</th>\n",
       "      <th>tail_mean_gap</th>\n",
       "      <th>es_bias</th>\n",
       "      <th>es_mae</th>\n",
       "      <th>es_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>95%</td>\n",
       "      <td>1522</td>\n",
       "      <td>101</td>\n",
       "      <td>0.066360</td>\n",
       "      <td>-0.026262</td>\n",
       "      <td>-0.027861</td>\n",
       "      <td>-0.001598</td>\n",
       "      <td>-0.001598</td>\n",
       "      <td>0.008643</td>\n",
       "      <td>0.016601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>99%</td>\n",
       "      <td>1522</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010512</td>\n",
       "      <td>-0.050760</td>\n",
       "      <td>-0.058280</td>\n",
       "      <td>-0.007519</td>\n",
       "      <td>-0.007519</td>\n",
       "      <td>0.012971</td>\n",
       "      <td>0.016545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentiment</td>\n",
       "      <td>95%</td>\n",
       "      <td>1533</td>\n",
       "      <td>120</td>\n",
       "      <td>0.078278</td>\n",
       "      <td>-0.024570</td>\n",
       "      <td>-0.025258</td>\n",
       "      <td>-0.000689</td>\n",
       "      <td>-0.000689</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.014203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentiment</td>\n",
       "      <td>99%</td>\n",
       "      <td>1533</td>\n",
       "      <td>19</td>\n",
       "      <td>0.012394</td>\n",
       "      <td>-0.046428</td>\n",
       "      <td>-0.045471</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.011725</td>\n",
       "      <td>0.017223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model Level  n_obs  n_viol  viol_rate  realized_tail_mean  \\\n",
       "0   Baseline   95%   1522     101   0.066360           -0.026262   \n",
       "1   Baseline   99%   1522      16   0.010512           -0.050760   \n",
       "2  Sentiment   95%   1533     120   0.078278           -0.024570   \n",
       "3  Sentiment   99%   1533      19   0.012394           -0.046428   \n",
       "\n",
       "   pred_es_tail_mean  tail_mean_gap   es_bias    es_mae   es_rmse  \n",
       "0          -0.027861      -0.001598 -0.001598  0.008643  0.016601  \n",
       "1          -0.058280      -0.007519 -0.007519  0.012971  0.016545  \n",
       "2          -0.025258      -0.000689 -0.000689  0.008222  0.014203  \n",
       "3          -0.045471       0.000957  0.000957  0.011725  0.017223  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 5 (optional): Compact comparison table\n",
    "comparison = pd.DataFrame([\n",
    "    {\"Model\": \"Baseline\", \"Level\": \"95%\", **{k: v for k, v in baseline_95.items() if k not in [\"alpha\"]}},\n",
    "    {\"Model\": \"Baseline\", \"Level\": \"99%\", **{k: v for k, v in baseline_99.items() if k not in [\"alpha\"]}},\n",
    "    {\"Model\": \"Sentiment\", \"Level\": \"95%\", **{k: v for k, v in sentiment_95.items() if k not in [\"alpha\"]}},\n",
    "    {\"Model\": \"Sentiment\", \"Level\": \"99%\", **{k: v for k, v in sentiment_99.items() if k not in [\"alpha\"]}},\n",
    "])\n",
    "\n",
    "comparison[[\n",
    "    \"Model\", \"Level\", \"n_obs\", \"n_viol\", \"viol_rate\",\n",
    "    \"realized_tail_mean\", \"pred_es_tail_mean\", \"tail_mean_gap\",\n",
    "    \"es_bias\", \"es_mae\", \"es_rmse\"\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8411aeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE ARTIFACTS FOR TABLES/PLOTS (no recomputation in reporting notebook)\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_DIR = Path(\"../data/processed/evaluation\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Use full result files for table stats to avoid accidental mutation from earlier cells.\n",
    "base_full = pd.read_csv(\"../data/processed/baseline_results.csv\", parse_dates=[\"Date\"])\n",
    "sent_full = pd.read_csv(\"../data/processed/sentiment_results.csv\", parse_dates=[\"Date\"])\n",
    "\n",
    "for _df in [base_full, sent_full]:\n",
    "    _df[\"violation_95\"] = (_df[\"y_real\"] < _df[\"VaR_95\"]).astype(int)\n",
    "    _df[\"violation_99\"] = (_df[\"y_real\"] < _df[\"VaR_99\"]).astype(int)\n",
    "\n",
    "# ---------------------------\n",
    "# Table 1: VaR Backtesting Summary\n",
    "# ---------------------------\n",
    "var_rows = []\n",
    "for model_name, _df in [(\"Baseline\", base_full), (\"Sentiment\", sent_full)]:\n",
    "    for level, alpha_tail, vcol in [(\"95%\", 0.05, \"violation_95\"), (\"99%\", 0.01, \"violation_99\")]:\n",
    "        n_obs = int(len(_df))\n",
    "        n_viol = int(_df[vcol].sum())\n",
    "        var_rows.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Confidence\": level,\n",
    "            \"Observations\": n_obs,\n",
    "            \"Violations\": n_viol,\n",
    "            \"Violation rate\": n_viol / n_obs if n_obs else np.nan,\n",
    "            \"Expected rate\": alpha_tail,\n",
    "        })\n",
    "\n",
    "var_backtesting_summary = pd.DataFrame(var_rows)\n",
    "var_backtesting_summary.to_csv(OUT_DIR / \"var_backtesting_summary.csv\", index=False)\n",
    "\n",
    "# ---------------------------\n",
    "# Kupiec / Christoffersen summaries\n",
    "# ---------------------------\n",
    "kupiec_summary = pd.DataFrame([\n",
    "    {\"Model\": \"Baseline\",  \"Confidence\": \"95%\", \"LR_uc\": LR_b_95, \"p_value\": p_b_95},\n",
    "    {\"Model\": \"Sentiment\", \"Confidence\": \"95%\", \"LR_uc\": LR_s_95, \"p_value\": p_s_95},\n",
    "    {\"Model\": \"Baseline\",  \"Confidence\": \"99%\", \"LR_uc\": LR_b_99, \"p_value\": p_b_99},\n",
    "    {\"Model\": \"Sentiment\", \"Confidence\": \"99%\", \"LR_uc\": LR_s_99, \"p_value\": p_s_99},\n",
    "])\n",
    "kupiec_summary.to_csv(OUT_DIR / \"kupiec_summary.csv\", index=False)\n",
    "\n",
    "christoffersen_summary = pd.DataFrame([\n",
    "    {\"Model\": \"Baseline\",  \"Confidence\": \"95%\", \"LR_ind\": LR_b_95_ind, \"p_value\": p_b_95_ind},\n",
    "    {\"Model\": \"Sentiment\", \"Confidence\": \"95%\", \"LR_ind\": LR_s_95_ind, \"p_value\": p_s_95_ind},\n",
    "    {\"Model\": \"Baseline\",  \"Confidence\": \"99%\", \"LR_ind\": LR_b_99_ind, \"p_value\": p_b_99_ind},\n",
    "    {\"Model\": \"Sentiment\", \"Confidence\": \"99%\", \"LR_ind\": LR_s_99_ind, \"p_value\": p_s_99_ind},\n",
    "])\n",
    "christoffersen_summary.to_csv(OUT_DIR / \"christoffersen_summary.csv\", index=False)\n",
    "\n",
    "# ---------------------------\n",
    "# Table 2: Empirical ES Evaluation Summary\n",
    "# ---------------------------\n",
    "es_empirical_summary = pd.DataFrame([\n",
    "    {\"Model\": \"Baseline\",  \"Confidence\": \"95%\", **{k: v for k, v in baseline_95.items() if k != \"alpha\"}},\n",
    "    {\"Model\": \"Baseline\",  \"Confidence\": \"99%\", **{k: v for k, v in baseline_99.items() if k != \"alpha\"}},\n",
    "    {\"Model\": \"Sentiment\", \"Confidence\": \"95%\", **{k: v for k, v in sentiment_95.items() if k != \"alpha\"}},\n",
    "    {\"Model\": \"Sentiment\", \"Confidence\": \"99%\", **{k: v for k, v in sentiment_99.items() if k != \"alpha\"}},\n",
    "])\n",
    "\n",
    "# Rename to thesis-friendly labels\n",
    "es_empirical_summary = es_empirical_summary.rename(columns={\n",
    "    \"n_obs\": \"Observations\",\n",
    "    \"n_viol\": \"Violations\",\n",
    "    \"viol_rate\": \"Violation rate\",\n",
    "    \"realized_tail_mean\": \"Realized tail mean\",\n",
    "    \"pred_es_tail_mean\": \"Predicted ES mean (violations)\",\n",
    "    \"tail_mean_gap\": \"Tail mean gap (ES_pred - realized)\",\n",
    "    \"es_bias\": \"ES Bias\",\n",
    "    \"es_mae\": \"ES MAE\",\n",
    "    \"es_rmse\": \"ES RMSE\",\n",
    "})\n",
    "es_empirical_summary.to_csv(OUT_DIR / \"es_empirical_summary.csv\", index=False)\n",
    "\n",
    "# ---------------------------\n",
    "# DM test summary\n",
    "# ---------------------------\n",
    "dm_summary = pd.DataFrame([\n",
    "    {\"Confidence\": \"95%\", \"DM statistic\": DM_95, \"p_value\": p_95, \"mean_loss_diff_sent_minus_base\": mean_diff_95},\n",
    "    {\"Confidence\": \"99%\", \"DM statistic\": DM_99, \"p_value\": p_99, \"mean_loss_diff_sent_minus_base\": mean_diff_99},\n",
    "])\n",
    "dm_summary.to_csv(OUT_DIR / \"dm_test_summary.csv\", index=False)\n",
    "\n",
    "# ---------------------------\n",
    "# Plot-ready source (95%) so plotting notebook doesn't recompute joins/violations\n",
    "# ---------------------------\n",
    "plot_95 = (\n",
    "    base_full[[\"Date\", \"y_real\", \"VaR_95\", \"ES_95\", \"violation_95\"]]\n",
    "    .rename(columns={\n",
    "        \"y_real\": \"y_real_baseline\",\n",
    "        \"VaR_95\": \"VaR_95_baseline\",\n",
    "        \"ES_95\": \"ES_95_baseline\",\n",
    "        \"violation_95\": \"violation_95_baseline\",\n",
    "    })\n",
    "    .merge(\n",
    "        sent_full[[\"Date\", \"y_real\", \"VaR_95\", \"ES_95\", \"violation_95\"]]\n",
    "        .rename(columns={\n",
    "            \"y_real\": \"y_real_sentiment\",\n",
    "            \"VaR_95\": \"VaR_95_sentiment\",\n",
    "            \"ES_95\": \"ES_95_sentiment\",\n",
    "            \"violation_95\": \"violation_95_sentiment\",\n",
    "        }),\n",
    "        on=\"Date\",\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    .sort_values(\"Date\")\n",
    ")\n",
    "plot_95.to_csv(OUT_DIR / \"plot_source_95.csv\", index=False)\n",
    "\n",
    "\n",
    "# Additional per-model and 99% plot artifacts\n",
    "base_full.to_csv(OUT_DIR / \"baseline_oos_with_violations.csv\", index=False)\n",
    "sent_full.to_csv(OUT_DIR / \"sentiment_oos_with_violations.csv\", index=False)\n",
    "\n",
    "base_full.loc[base_full[\"violation_95\"] == 1, [\"Date\", \"y_real\", \"VaR_95\", \"ES_95\"]].to_csv(OUT_DIR / \"baseline_tail_95.csv\", index=False)\n",
    "base_full.loc[base_full[\"violation_99\"] == 1, [\"Date\", \"y_real\", \"VaR_99\", \"ES_99\"]].to_csv(OUT_DIR / \"baseline_tail_99.csv\", index=False)\n",
    "\n",
    "sent_full.loc[sent_full[\"violation_95\"] == 1, [\"Date\", \"y_real\", \"VaR_95\", \"ES_95\"]].to_csv(OUT_DIR / \"sentiment_tail_95.csv\", index=False)\n",
    "sent_full.loc[sent_full[\"violation_99\"] == 1, [\"Date\", \"y_real\", \"VaR_99\", \"ES_99\"]].to_csv(OUT_DIR / \"sentiment_tail_99.csv\", index=False)\n",
    "\n",
    "plot_99 = (\n",
    "    base_full[[\"Date\", \"y_real\", \"VaR_99\", \"ES_99\", \"violation_99\"]]\n",
    "    .rename(columns={\n",
    "        \"y_real\": \"y_real_baseline\",\n",
    "        \"VaR_99\": \"VaR_99_baseline\",\n",
    "        \"ES_99\": \"ES_99_baseline\",\n",
    "        \"violation_99\": \"violation_99_baseline\",\n",
    "    })\n",
    "    .merge(\n",
    "        sent_full[[\"Date\", \"y_real\", \"VaR_99\", \"ES_99\", \"violation_99\"]]\n",
    "        .rename(columns={\n",
    "            \"y_real\": \"y_real_sentiment\",\n",
    "            \"VaR_99\": \"VaR_99_sentiment\",\n",
    "            \"ES_99\": \"ES_99_sentiment\",\n",
    "            \"violation_99\": \"violation_99_sentiment\",\n",
    "        }),\n",
    "        on=\"Date\",\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    .sort_values(\"Date\")\n",
    ")\n",
    "plot_99.to_csv(OUT_DIR / \"plot_source_99.csv\", index=False)\n",
    "\n",
    "print(\"- baseline_oos_with_violations.csv\")\n",
    "print(\"- sentiment_oos_with_violations.csv\")\n",
    "print(\"- baseline_tail_95.csv\")\n",
    "print(\"- baseline_tail_99.csv\")\n",
    "print(\"- sentiment_tail_95.csv\")\n",
    "print(\"- sentiment_tail_99.csv\")\n",
    "print(\"- plot_source_99.csv\")\n",
    "\n",
    "print(\"Saved evaluation artifacts to:\", OUT_DIR.resolve())\n",
    "print(\"- var_backtesting_summary.csv\")\n",
    "print(\"- es_empirical_summary.csv\")\n",
    "print(\"- kupiec_summary.csv\")\n",
    "print(\"- christoffersen_summary.csv\")\n",
    "print(\"- dm_test_summary.csv\")\n",
    "print(\"- plot_source_95.csv\")\n",
    "\n",
    "var_backtesting_summary, es_empirical_summary\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}